{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "126. 单词接龙 II\n",
    "按字典 wordList 完成从单词 beginWord 到单词 endWord 转化，一个表示此过程的 转换序列 是形式上像 beginWord -> s1 -> s2 -> ... -> sk 这样的单词序列，并满足：\n",
    "\n",
    "每对相邻的单词之间仅有单个字母不同。\n",
    "转换过程中的每个单词 si（1 <= i <= k）必须是字典 wordList 中的单词。注意，beginWord 不必是字典 wordList 中的单词。\n",
    "sk == endWord\n",
    "给你两个单词 beginWord 和 endWord ，以及一个字典 wordList 。请你找出并返回所有从 beginWord 到 endWord 的 最短转换序列 ，如果不存在这样的转换序列，返回一个空列表。每个序列都应该以单词列表 [beginWord, s1, s2, ..., sk] 的形式返回。\n",
    "\n",
    " \n",
    "\n",
    "示例 1：\n",
    "\n",
    "输入：beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "输出：[[\"hit\",\"hot\",\"dot\",\"dog\",\"cog\"],[\"hit\",\"hot\",\"lot\",\"log\",\"cog\"]]\n",
    "解释：存在 2 种最短的转换序列：\n",
    "\"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> \"cog\"\n",
    "\"hit\" -> \"hot\" -> \"lot\" -> \"log\" -> \"cog\"\n",
    "示例 2：\n",
    "\n",
    "输入：beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n",
    "输出：[]\n",
    "解释：endWord \"cog\" 不在字典 wordList 中，所以不存在符合要求的转换序列。\n",
    " \n",
    "\n",
    "提示：\n",
    "\n",
    "1 <= beginWord.length <= 5\n",
    "endWord.length == beginWord.length\n",
    "1 <= wordList.length <= 500\n",
    "wordList[i].length == beginWord.length\n",
    "beginWord、endWord 和 wordList[i] 由小写英文字母组成\n",
    "beginWord != endWord\n",
    "wordList 中的所有单词 互不相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "127. 单词接龙\n",
    "字典 wordList 中从单词 beginWord 和 endWord 的 转换序列 是一个按下述规格形成的序列 beginWord -> s1 -> s2 -> ... -> sk：\n",
    "\n",
    "每一对相邻的单词只差一个字母。\n",
    " 对于 1 <= i <= k 时，每个 si 都在 wordList 中。注意， beginWord 不需要在 wordList 中。\n",
    "sk == endWord\n",
    "给你两个单词 beginWord 和 endWord 和一个字典 wordList ，返回 从 beginWord 到 endWord 的 最短转换序列 中的 单词数目 。如果不存在这样的转换序列，返回 0 。\n",
    "\n",
    " \n",
    "示例 1：\n",
    "\n",
    "输入：beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "输出：5\n",
    "解释：一个最短转换序列是 \"hit\" -> \"hot\" -> \"dot\" -> \"dog\" -> \"cog\", 返回它的长度 5。\n",
    "示例 2：\n",
    "\n",
    "输入：beginWord = \"hit\", endWord = \"cog\", wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n",
    "输出：0\n",
    "解释：endWord \"cog\" 不在字典中，所以无法进行转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是说这两道题一个是返回列表，一个是返回列表的长度。\n",
    "本题只需要求出最短长度就可以了，不用找出路径。\n",
    "\n",
    "所以这道题要解决两个问题：\n",
    "\n",
    "图中的线是如何连在一起的\n",
    "起点和终点的最短路径长度\n",
    "首先题目中并没有给出点与点之间的连线，而是要我们自己去连，条件是字符只能差一个，所以判断点与点之间的关系，要自己判断是不是差一个字符，如果差一个字符，那就是有链接。\n",
    "\n",
    "然后就是求起点和终点的最短路径长度，这里无向图求最短路，广搜最为合适，广搜只要搜到了终点，那么一定是最短的路径。因为广搜就是以起点中心向四周扩散的搜索。\n",
    "\n",
    "本题如果用深搜，会比较麻烦，要在到达终点的不同路径中选则一条最短路。 而广搜只要达到终点，一定是最短路。\n",
    "\n",
    "另外需要有一个注意点：\n",
    "\n",
    "本题是一个无向图，需要用标记位，标记着节点是否走过，否则就会死循环！\n",
    "本题给出集合是数组型的，可以转成set结构，查找更快一些\n",
    "C++代码如下：（详细注释）\n",
    "\n",
    "class Solution {\n",
    "public:\n",
    "    int ladderLength(string beginWord, string endWord, vector<string>& wordList) {\n",
    "        // 将vector转成unordered_set，提高查询速度\n",
    "        unordered_set<string> wordSet(wordList.begin(), wordList.end());\n",
    "        // 如果endWord没有在wordSet出现，直接返回0\n",
    "        if (wordSet.find(endWord) == wordSet.end()) return 0;\n",
    "        // 记录word是否访问过\n",
    "        unordered_map<string, int> visitMap; // <word, 查询到这个word路径长度>\n",
    "        // 初始化队列\n",
    "        queue<string> que;\n",
    "        que.push(beginWord);\n",
    "        // 初始化visitMap\n",
    "        visitMap.insert(pair<string, int>(beginWord, 1));\n",
    "\n",
    "        while(!que.empty()) {\n",
    "            string word = que.front();\n",
    "            que.pop();\n",
    "            int path = visitMap[word]; // 这个word的路径长度\n",
    "            for (int i = 0; i < word.size(); i++) {\n",
    "                string newWord = word; // 用一个新单词替换word，因为每次置换一个字母\n",
    "                for (int j = 0 ; j < 26; j++) {\n",
    "                    newWord[i] = j + 'a';\n",
    "                    if (newWord == endWord) return path + 1; // 找到了end，返回path+1\n",
    "                    // wordSet出现了newWord，并且newWord没有被访问过\n",
    "                    if (wordSet.find(newWord) != wordSet.end()\n",
    "                            && visitMap.find(newWord) == visitMap.end()) {\n",
    "                        // 添加访问信息\n",
    "                        visitMap.insert(pair<string, int>(newWord, path + 1));\n",
    "                        que.push(newWord);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return 0;\n",
    "    }\n",
    "};\n",
    "当然本题也可以用双向BFS，就是从头尾两端进行搜索，大家感兴趣，可以自己去实现，这里就不再做详细讲解了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里涉及到了图，我们可以看一下\n",
    "743. 网络延迟时间\n",
    "有 n 个网络节点，标记为 1 到 n。\n",
    "\n",
    "给你一个列表 times，表示信号经过 有向 边的传递时间。 times[i] = (ui, vi, wi)，其中 ui 是源节点，vi 是目标节点， wi 是一个信号从源节点传递到目标节点的时间。\n",
    "\n",
    "现在，从某个节点 K 发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回 -1 。\n",
    "\n",
    " \n",
    "\n",
    "示例 1：\n",
    "\n",
    "\n",
    "\n",
    "输入：times = [[2,1,1],[2,3,1],[3,4,1]], n = 4, k = 2\n",
    "输出：2\n",
    "示例 2：\n",
    "\n",
    "输入：times = [[1,2,1]], n = 2, k = 1\n",
    "输出：1\n",
    "示例 3：\n",
    "\n",
    "输入：times = [[1,2,1]], n = 2, k = 2\n",
    "输出：-1\n",
    " \n",
    "\n",
    "提示：\n",
    "\n",
    "1 <= k <= n <= 100\n",
    "1 <= times.length <= 6000\n",
    "times[i].length == 3\n",
    "1 <= ui, vi <= n\n",
    "ui != vi\n",
    "0 <= wi <= 100\n",
    "所有 (ui, vi) 对都 互不相同（即，不含重复边）\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution_743:\n",
    "    def networkDelayTime(self, times: List[List[int]], n: int, k: int) -> int:\n",
    "        # 创建一个字典列表，每个字典保存的是times[i] = (ui, vi, wi)中的[ui, vi]：wi\n",
    "        map1 = [{}for i in range(n+1)]\n",
    "        for i in times:\n",
    "            map1[i[0]][i[1]] = i[2]\n",
    "        # 初试华发送节点，默认不能收到\n",
    "        sent = [-1 for i in range(n+1)]\n",
    "        # 第k个节点是始发，默认为0\n",
    "        sent[k] = 0\n",
    "        from collections import deque\n",
    "        # 队列保存当前所到节点以及所用时间\n",
    "        deq = deque([[k,0]])\n",
    "\n",
    "        while deq:\n",
    "            cur, time = deq.popleft()\n",
    "            # 此时v是要到达的目标节点，t是所需时间\n",
    "            for v,t in map1[cur].items():\n",
    "                tmp = time + t\n",
    "                # -1即未曾到达\n",
    "                if sent[v] == -1 or sent[v] > tmp:\n",
    "                    sent[v] = tmp\n",
    "                    deq.append([v,tmp])\n",
    "        # 有一个未曾到达就直接返回-1\n",
    "        if -1 in sent[1:n+1]:\n",
    "            return -1\n",
    "        else:\n",
    "            return max(sent[1:n+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = [[2,1,1],[2,3,1],[3,4,1]]\n",
    "n = 4\n",
    "k = 2\n",
    "s_743 = Solution_743()\n",
    "s_743.networkDelayTime(times,n,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "class Solution:\n",
    "    def ladderLength_1(self, beginWord: str, endWord: str, wordList: List[str]) -> List:\n",
    "        wordList.append(beginWord)\n",
    "        # print(\"wordList:\", wordList)\n",
    "        ### 构建具有邻接关系的桶\n",
    "        buckets = defaultdict(list)\n",
    "        # print(\"buckets1:\", buckets)\n",
    "        for word in wordList:\n",
    "            for i in range(len(beginWord)):\n",
    "                # print(\"word[:i]:\", word[:i])\n",
    "                # print(\"word[i+1:]:\", word[i+1:])\n",
    "                # 以当前字母为基准，对当前word划分为两部分，\n",
    "                # 允许有n个不同就i+n，同样的'_'就会有几个，'_'代表可变字母，即word[i]，\n",
    "                # 此处len(word) == len(beginword)\n",
    "                # 以给出示例，则有：\n",
    "                # buckets2: defaultdict(<class 'list'>, \n",
    "                # {'_ot': ['hot', 'dot', 'lot'], \n",
    "                # 'h_t': ['hot', 'hit'], \n",
    "                # 'ho_': ['hot'], \n",
    "                # 'd_t': ['dot'], \n",
    "                # 'do_': ['dot', 'dog'], \n",
    "                # '_og': ['dog', 'log', 'cog'], \n",
    "                # 'd_g': ['dog'], \n",
    "                # 'l_t': ['lot'], \n",
    "                # 'lo_': ['lot', 'log'], \n",
    "                # 'l_g': ['log'], \n",
    "                # 'c_g': ['cog'], \n",
    "                # 'co_': ['cog'], \n",
    "                # '_it': ['hit'], \n",
    "                # 'hi_': ['hit']})\n",
    "                match = word[:i] + '_' + word[i+1:]\n",
    "                # print(\"match:\", match)\n",
    "                buckets[match].append(word)\n",
    "                # print(\"buckets2:\", buckets)\n",
    "        ##### BFS遍历\n",
    "        # 前溯词列表\n",
    "        preWords = defaultdict(list)\n",
    "        # 待遍历词及深度  \n",
    "        toSeen = deque([(beginWord, 1)])  \n",
    "        # 已探测词列表\n",
    "        beFound = {beginWord:1}  \n",
    "        while toSeen:\n",
    "            curWord, level = toSeen.popleft()\n",
    "            for i in range(len(beginWord)):\n",
    "                # 此处又有以当前字母为基准，对当前要遍历word划分为两部分\n",
    "                match = curWord[:i] + '_' + curWord[i+1:]\n",
    "                # 对match对应的value，也就是包含其的所有word遍历\n",
    "                for word in buckets[match]:\n",
    "                    # 如果没有探测过，就加到已探测词字典中和待遍历的字典中\n",
    "                    if word not in beFound:\n",
    "                        beFound[word] = level+1\n",
    "                        toSeen.append((word, level+1))\n",
    "                    # 不管有没有探测过，如果当前深度等于该词首次遍历深度，则仍应加入前溯词列表\n",
    "                    if beFound[word] == level+1:  \n",
    "                        preWords[word].append(curWord)\n",
    "            # 如果endWord 已探测并且完成当前层遍历，即可进行下一步遍历，这一步是否需要完成当前层遍历？\n",
    "            if endWord in beFound and level+1 > beFound[endWord]:\n",
    "                break\n",
    "        # 到这一步就是127.结果\n",
    "        # print(\"befound[endWord]:\", beFound[endWord])\n",
    "        # print(\"preWords:\", preWords)\n",
    "        \n",
    "        #### 列表推导式输出结果\n",
    "        if endWord in beFound:\n",
    "            res = [[endWord]]\n",
    "            while res[0][0] != beginWord:\n",
    "                # 通过这个生成器内部的魔法函数或者运算重载进行其他数据类型的变化\n",
    "                # 例如在此生成器两边加入中括号[] 就会将生成器对象构成并返回一个新的列表，\n",
    "                # 上面while读取的是新生成的res，不再是[[endWord]]\n",
    "                res = [[word] + r for r in res for word in preWords[r[0]]] \n",
    "                \n",
    "            return res\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def ladderLength_2(self, beginWord: str, endWord: str, wordList: List[str]) -> int:\n",
    "        wordSet = set(wordList)\n",
    "        if len(wordSet)== 0 or endWord not in wordSet:\n",
    "            return 0\n",
    "        mapping = {beginWord:1}\n",
    "        queue = deque([beginWord]) \n",
    "        while queue:\n",
    "            word = queue.popleft()\n",
    "            path = mapping[word]\n",
    "            for i in range(len(word)):\n",
    "                word_list = list(word)\n",
    "                for j in range(26):\n",
    "                    word_list[i] = chr(ord('a')+j)\n",
    "                    newWord = \"\".join(word_list)\n",
    "                    if newWord == endWord:\n",
    "                        return path+1\n",
    "                    if newWord in wordSet and newWord not in mapping:\n",
    "                        mapping[newWord] = path+1\n",
    "                        queue.append(newWord)                      \n",
    "        return 0\n",
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n",
    "s = Solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preWords: defaultdict(<class 'list'>, {'hot': ['hit'], 'dot': ['hot'], 'lot': ['hot'], 'dog': ['dot'], 'log': ['lot'], 'cog': ['dog', 'log']})\n",
      "[['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(s.ladderLength_1(beginWord, endWord, wordList))\n",
    "print(s.ladderLength_2(beginWord, endWord, wordList))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([('hit', ['hit'])])\n",
      "('hit', ['hit'])\n"
     ]
    }
   ],
   "source": [
    "queue = deque([(beginWord, [beginWord])]) \n",
    "print(queue)\n",
    "a = queue.popleft()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res: [['dog', 'cog'], ['log', 'cog']]\n",
      "res: [['dot', 'dog', 'cog'], ['lot', 'log', 'cog']]\n",
      "res: [['hot', 'dot', 'dog', 'cog'], ['hot', 'lot', 'log', 'cog']]\n",
      "res: [['hit', 'hot', 'dot', 'dog', 'cog'], ['hit', 'hot', 'lot', 'log', 'cog']]\n"
     ]
    }
   ],
   "source": [
    "preWords = {'hot': ['hit'], 'dot': ['hot'], 'lot': ['hot'], 'dog': ['dot'], 'log': ['lot'], 'cog': ['dog', 'log']}\n",
    "res = [['cog']]\n",
    "\n",
    "while res[0][0] != beginWord:\n",
    "    res = [[word] + r for r in res for word in preWords[r[0]]]\n",
    "    print(\"res:\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: ['cog']\n",
      "word: dog\n",
      "tmp: ['dog', 'cog']\n",
      "word: log\n",
      "tmp: ['log', 'cog']\n",
      "r: ['dog', 'cog']\n",
      "word: dot\n",
      "tmp: ['dot', 'dog', 'cog']\n",
      "r: ['log', 'cog']\n",
      "word: lot\n",
      "tmp: ['lot', 'log', 'cog']\n",
      "r: ['dot', 'dog', 'cog']\n",
      "word: hot\n",
      "tmp: ['hot', 'dot', 'dog', 'cog']\n",
      "r: ['lot', 'log', 'cog']\n",
      "word: hot\n",
      "tmp: ['hot', 'lot', 'log', 'cog']\n",
      "r: ['hot', 'dot', 'dog', 'cog']\n",
      "word: hit\n",
      "tmp: ['hit', 'hot', 'dot', 'dog', 'cog']\n",
      "r: ['hot', 'lot', 'log', 'cog']\n",
      "word: hit\n",
      "tmp: ['hit', 'hot', 'lot', 'log', 'cog']\n",
      "r: ['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_29032/3111196918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"r:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreWords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hit'"
     ]
    }
   ],
   "source": [
    "beginWord = \"hit\"\n",
    "endWord = \"cog\"\n",
    "preWords = {'hot': ['hit'], 'dot': ['hot'], 'lot': ['hot'], 'dog': ['dot'], 'log': ['lot'], 'cog': ['dog', 'log']}\n",
    "res = [['cog']]\n",
    "# 不会分解\n",
    "while res[0][0] != beginWord:\n",
    "    # res = [[word] + r for r in res for word in preWords[r[0]]]\n",
    "    for r in res:\n",
    "        print(\"r:\", r)\n",
    "        for word in preWords[r[0]]:\n",
    "            print(\"word:\", word)\n",
    "            tmp = [word] + r\n",
    "            print(\"tmp:\", tmp)\n",
    "            res.extend([tmp])\n",
    "print(\"res:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "820d776940a02930c69820a8cec178404e4e9e60b6116e2717a21913b50566a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
